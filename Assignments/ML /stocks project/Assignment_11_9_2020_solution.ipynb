{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Project\n",
    "\n",
    "In this Capstone Project we will be engaging with the stock price data for several hundred stocks over 5 years, which can be found at:\n",
    "(./Data/prices-split-adjusted.csv.zip).  The data is from [Kaggle](https://www.kaggle.com/dgawlik/nyse#prices-split-adjusted.csv) and is available in its original form there under a CC0 license. We will be using a slightly preprocessed version in the repo.  \n",
    "\n",
    "In this notebook we will be looking at financial forecasting with machine learning.  This is inherently one of the hardest problems in machine learning, because some of the most advanced and well-funded technical teams in the world are trying to use machine learning and other techniques to find patterns in the financial data.  When they find patterns and if they trade on those findings, prices will move in a way that makes those patterns less pronounced over time. This is not to say that this is not a fun and rewarding area.  Just do not get discouraged if you don't find an instant money machine.  \n",
    "\n",
    "### Outline:\n",
    "0. Background\n",
    "\n",
    "1. Preparing our tools\n",
    "\n",
    "2. Importing and describing the data.\n",
    "\n",
    "3. Exploring, cleaning and visualizing the data\n",
    "\n",
    "3. Developing analytics\n",
    "\n",
    "4. Preparing and splitting our data\n",
    "\n",
    "5. Building our first model\n",
    "\n",
    "6. Extending to other ML models\n",
    "\n",
    "7. Ideas for further strategies\n",
    "\n",
    "8. Wrapping up\n",
    "\n",
    "### Options\n",
    "As we progress you are encouraged to take this dataset further. You are also encouraged to explore any aspects of the data. Develop your own algorithms. Be explicit about your inquiry and success in predicting effects on our world.\n",
    "\n",
    "### Warning: Not financial advice\n",
    "This exercise is meant purely for educational purposes, uses many simplifications and is not intended, nor should be considered as financial advice. There are many risks involved in implementation of financial trading strategies that are not considered nor described here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up\n",
    "If you have not yet set up your environment, you can easily do so with VS Code, and the python extension and Anaconda.  \n",
    "\n",
    "For VSCode go here: [https://code.visualstudio.com/]\n",
    "\n",
    "and then you can follow these instructions:\n",
    "[https://code.visualstudio.com/docs/python/data-science-tutorial]\n",
    "\n",
    "0. Background\n",
    "\n",
    "Machine learning is of increasing importance in finance. As volumes of data grow ever faster, the need for machine driven models to find patterns in that data becomes ever more important.  In the ever-accelerating race to better process data into predictions about securities prices, machine learning has become an important tool, because it is good at finding patterns in large amounts of data.  Today we will be examining patterns in stock prices themselves to practice developing models to predict future set prices. If there are systematic trends, patterns or reversals, then we may detect them. \n",
    "\n",
    "While the chances that we discover totally new and unexploited price patterns today is low, we will practice organizing our data, creating and analyzing machine learning models that will give us the tools to develop state of the art signals of value.\n",
    "\n",
    "Goals: \n",
    "\n",
    "1. Become familiar and practice the process of building machine learning models as they relate to financial data.  \n",
    "\n",
    "2. Understand the special processing that is required when working with time series data such those found in finance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preparing our tools.\n",
    "\n",
    "Let's review our standard imports:\n",
    "- numpy for rapid numerical calculations with fast vectorized C implementations\n",
    "- pandas for processing data\n",
    "- matplotlib and Seaborn for visualizing charts\n",
    "- scikit-learn (imported as sklearn) is the de facto standard machine learning library in the pydata ecosystem.  \n",
    " \n",
    "Additionally, we will be using [pandas_profiling](https://github.com/pandas-profiling/pandas-profiling) which is a newer convenience package that helps by putting together much of our initial *boilerplate* exploratory data analysis code. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring our tools in:\n",
    "import numpy             as np\n",
    "import pandas            as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing and describing the data\n",
    "\n",
    "Now we are ready to import our data.  The value rows can be set if you only want to import a small subset due to computer memory or speed constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are using information from the data source description to know that date is a column containing just what is says\n",
    "rows = None\n",
    "stocks = pd.read_csv('./Data/prices-split-adjusted.csv.zip', nrows=rows, parse_dates=['date'], index_col='date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data successfully loaded, let's explore what we have. First, summarize the dataframe via the info method to validate the data reading and parsing.  When looking at the info report, it is best practice to note that each column is the expected type, noting that strings are reported as object.  Also note if there are null values, how many values there are and what the columns are.  \n",
    "\n",
    "We do not have a data dictionary in this case.  But if you were lucky enough to have access to a data dictionary, this is a good time to check that the dictionary matches what you actually have.  Discrepancies could be the result of mis-parsing, undocumented schema changes, documentation that is not up to date, or a number of other reasons.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 851264 entries, 2016-01-05 to 2016-12-30\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   symbol  851264 non-null  object \n",
      " 1   open    851264 non-null  float64\n",
      " 2   close   851264 non-null  float64\n",
      " 3   low     851264 non-null  float64\n",
      " 4   high    851264 non-null  float64\n",
      " 5   volume  851264 non-null  float64\n",
      "dtypes: float64(5), object(1)\n",
      "memory usage: 45.5+ MB\n"
     ]
    }
   ],
   "source": [
    "stocks.info() # Look at the descriptions of the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything looks as expected in info.  The string column symbol is the trading symbol, also known in finance as the ticker.  The dates were parsed as expected and all the other columns are numeric.  Now we can look at the first few rows of data to get a sample view.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>WLTW</td>\n",
       "      <td>123.430000</td>\n",
       "      <td>125.839996</td>\n",
       "      <td>122.309998</td>\n",
       "      <td>126.250000</td>\n",
       "      <td>2163600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-06</th>\n",
       "      <td>WLTW</td>\n",
       "      <td>125.239998</td>\n",
       "      <td>119.980003</td>\n",
       "      <td>119.940002</td>\n",
       "      <td>125.540001</td>\n",
       "      <td>2386400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-07</th>\n",
       "      <td>WLTW</td>\n",
       "      <td>116.379997</td>\n",
       "      <td>114.949997</td>\n",
       "      <td>114.930000</td>\n",
       "      <td>119.739998</td>\n",
       "      <td>2489500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-08</th>\n",
       "      <td>WLTW</td>\n",
       "      <td>115.480003</td>\n",
       "      <td>116.620003</td>\n",
       "      <td>113.500000</td>\n",
       "      <td>117.440002</td>\n",
       "      <td>2006300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-11</th>\n",
       "      <td>WLTW</td>\n",
       "      <td>117.010002</td>\n",
       "      <td>114.970001</td>\n",
       "      <td>114.089996</td>\n",
       "      <td>117.330002</td>\n",
       "      <td>1408600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-12</th>\n",
       "      <td>WLTW</td>\n",
       "      <td>115.510002</td>\n",
       "      <td>115.550003</td>\n",
       "      <td>114.500000</td>\n",
       "      <td>116.059998</td>\n",
       "      <td>1098000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-13</th>\n",
       "      <td>WLTW</td>\n",
       "      <td>116.459999</td>\n",
       "      <td>112.849998</td>\n",
       "      <td>112.589996</td>\n",
       "      <td>117.070000</td>\n",
       "      <td>949600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-14</th>\n",
       "      <td>WLTW</td>\n",
       "      <td>113.510002</td>\n",
       "      <td>114.379997</td>\n",
       "      <td>110.050003</td>\n",
       "      <td>115.029999</td>\n",
       "      <td>785300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-15</th>\n",
       "      <td>WLTW</td>\n",
       "      <td>113.330002</td>\n",
       "      <td>112.529999</td>\n",
       "      <td>111.919998</td>\n",
       "      <td>114.879997</td>\n",
       "      <td>1093700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-19</th>\n",
       "      <td>WLTW</td>\n",
       "      <td>113.660004</td>\n",
       "      <td>110.379997</td>\n",
       "      <td>109.870003</td>\n",
       "      <td>115.870003</td>\n",
       "      <td>1523500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           symbol        open       close         low        high     volume\n",
       "date                                                                        \n",
       "2016-01-05   WLTW  123.430000  125.839996  122.309998  126.250000  2163600.0\n",
       "2016-01-06   WLTW  125.239998  119.980003  119.940002  125.540001  2386400.0\n",
       "2016-01-07   WLTW  116.379997  114.949997  114.930000  119.739998  2489500.0\n",
       "2016-01-08   WLTW  115.480003  116.620003  113.500000  117.440002  2006300.0\n",
       "2016-01-11   WLTW  117.010002  114.970001  114.089996  117.330002  1408600.0\n",
       "2016-01-12   WLTW  115.510002  115.550003  114.500000  116.059998  1098000.0\n",
       "2016-01-13   WLTW  116.459999  112.849998  112.589996  117.070000   949600.0\n",
       "2016-01-14   WLTW  113.510002  114.379997  110.050003  115.029999   785300.0\n",
       "2016-01-15   WLTW  113.330002  112.529999  111.919998  114.879997  1093700.0\n",
       "2016-01-19   WLTW  113.660004  110.379997  109.870003  115.870003  1523500.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the head gives a good preview of a piece of the data, it may not be a great overall view of the entire dataset, especially for larger data sets or ones that may have been sorted at some point.  However, we are more comfortable that the dates were parsed correctly.  We can investigate numerical columns with describe.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>851264.000000</td>\n",
       "      <td>851264.000000</td>\n",
       "      <td>851264.000000</td>\n",
       "      <td>851264.000000</td>\n",
       "      <td>8.512640e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>64.993618</td>\n",
       "      <td>65.011913</td>\n",
       "      <td>64.336541</td>\n",
       "      <td>65.639748</td>\n",
       "      <td>5.415113e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>75.203893</td>\n",
       "      <td>75.201216</td>\n",
       "      <td>74.459518</td>\n",
       "      <td>75.906861</td>\n",
       "      <td>1.249468e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.660000</td>\n",
       "      <td>1.590000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.810000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31.270000</td>\n",
       "      <td>31.292776</td>\n",
       "      <td>30.940001</td>\n",
       "      <td>31.620001</td>\n",
       "      <td>1.221500e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>48.459999</td>\n",
       "      <td>48.480000</td>\n",
       "      <td>47.970001</td>\n",
       "      <td>48.959999</td>\n",
       "      <td>2.476250e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>75.120003</td>\n",
       "      <td>75.139999</td>\n",
       "      <td>74.400002</td>\n",
       "      <td>75.849998</td>\n",
       "      <td>5.222500e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1584.439941</td>\n",
       "      <td>1578.130005</td>\n",
       "      <td>1549.939941</td>\n",
       "      <td>1600.930054</td>\n",
       "      <td>8.596434e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                open          close            low           high  \\\n",
       "count  851264.000000  851264.000000  851264.000000  851264.000000   \n",
       "mean       64.993618      65.011913      64.336541      65.639748   \n",
       "std        75.203893      75.201216      74.459518      75.906861   \n",
       "min         1.660000       1.590000       1.500000       1.810000   \n",
       "25%        31.270000      31.292776      30.940001      31.620001   \n",
       "50%        48.459999      48.480000      47.970001      48.959999   \n",
       "75%        75.120003      75.139999      74.400002      75.849998   \n",
       "max      1584.439941    1578.130005    1549.939941    1600.930054   \n",
       "\n",
       "             volume  \n",
       "count  8.512640e+05  \n",
       "mean   5.415113e+06  \n",
       "std    1.249468e+07  \n",
       "min    0.000000e+00  \n",
       "25%    1.221500e+06  \n",
       "50%    2.476250e+06  \n",
       "75%    5.222500e+06  \n",
       "max    8.596434e+08  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Pandas Profiling\n",
    "Data exploration can start with a turnkey tool like pandas-profiling.  The important this with this is to make sure you actually look at the report and digest the output.  Make it the start of your investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructor note:\n",
    "\n",
    "Let students take a minute to look at this report.  See what they find.  You may want to do a think, pair, share or another form of reflection.  We run this report with minimal=True because the data set is large, and this avoids slow calculations.  \n",
    "\n",
    "Then go through the report and show students what they should be looking at for example: the number of variables, the number of observations, duplicate rows.  \n",
    "Be sure to point out that there is a warning that symbol has high cardinality. This warning is OK because we have data on a large number of stocks. It is expected with this data set and is typical of many finance data sets where there are many instruments.  \n",
    "\n",
    "Students may be interested to note the long tail in the numeric columns that can be seen in the histograms of each variable (in the variables section).  The histogram combines data from many different stocks so the variation in variables like closing price \"close\", or in \"volume\" is greater and shows a long tail.\n",
    "\n",
    "You can show the output in either a more dynamic widget or in an iframe using either of these lines of code:  \n",
    "\n",
    "profile.to_widgets()\n",
    "\n",
    "profile.to_notebook_iframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ec16e032b245eb91d59cb663eb81fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Summarize dataset', max=16.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7375e0e620f4ac49aee5bcc7d72859f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generate report structure', max=1.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Render widgets', max=1.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd1da80667bb40618735797aa062d087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Tab(children=(Tab(children=(GridBox(children=(VBox(children=(GridspecLayout(children=(HTML(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Minimal avoids expensive calculations that won't have much insight for us and are slow.\n",
    "profile = ProfileReport(stocks, minimal=True)\n",
    "profile.to_widgets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: \n",
    "\n",
    "Examine this report and see what insights you notice.  What do you notice about the data?  Are there ways to slice the data that would give more information?    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructor notes: \n",
    "Students can take a few minutes to do their own exploration.  If students don't see much or you covered this thoroughly, you can suggest that they dig into a particular stock by running a report on an individual stock, letting them choose their own symbol.  A sample code response follows the empty cell provided for student responses.  \n",
    "In the provided answer highlighting Microsoft, you can see that the variables have some tail, but not the same extremes as when many stocks were combined.  Point out that if they were doing this at work, they would probably look at each stock individually and really get to know their data.  Or at least do so for a representative sample, if not every stock.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blank cell left for student exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d895a4ce60047eb939c22c34dc89e9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Summarize dataset', max=16.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "222b3a95b2d84823ba4d6a830b4ab1d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generate report structure', max=1.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Render widgets', max=1.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c75faeb1e84ba5bab9f2db7924939f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Tab(children=(Tab(children=(GridBox(children=(VBox(children=(GridspecLayout(children=(HTML(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instructor sample answer\n",
    "profile = ProfileReport(stocks[stocks['symbol']=='MSFT'], minimal=False)\n",
    "profile.to_widgets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at an individual stock gives a much clearer impression of the distributions of each column.  Even if you can not do this for every stock, taking a sample can be very helpful.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Exploring, cleaning and visualizing the data\n",
    "\n",
    "#### Modeling our data\n",
    "One of the most important steps in preparing your data is to think of how we want to think about it.  For those who have worked with SQL, this is like identifying what the key to your table is. For this data exploration, we can think of the index into the data as being a a compound key of both the symbol (the ticker) and the date.  We will process the data in a way that will make a time series model for each stock.  Predicting the future based on what has happened in the past for that individual stock.  \n",
    "\n",
    "Thought Question: Can you think of other ways that you might want to consider this data?  What questions might prompt you to think of this data having a different data model?  The data model is not fixed but is a lens that lets us look at our data.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructor notes: (Sample answer) Perhaps we would be interested in studying certain holidays affect the variance in volumes?  Perhaps we have a hypothesis that just a few stocks heavily traded on holidays and most others have light trading.  Then we might only have the date as our key as we consider cross sectional data. \n",
    "\n",
    "Hopefully students will have other answers.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing our data\n",
    "It is often helpful to look at our data visually to see if there are any issues that \"look funny.\"  With experience, just looking at the data can help us understand it in a short amount of time.  This is often the step where domain expertise (in this case the financial markets) is especially useful.  Be sure to look at the histograms of the report above to see if they make sense to you.  \n",
    "\n",
    "Exercise: \n",
    "Are there other visualizations that would give you greater understanding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left blank for student answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-11</th>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-12</th>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-13</th>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-14</th>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-15</th>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-19</th>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-20</th>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-21</th>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-22</th>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-25</th>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-26</th>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-27</th>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-28</th>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-29</th>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-01</th>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            symbol\n",
       "date              \n",
       "2010-01-04     467\n",
       "2010-01-05     468\n",
       "2010-01-06     468\n",
       "2010-01-07     468\n",
       "2010-01-08     468\n",
       "2010-01-11     468\n",
       "2010-01-12     468\n",
       "2010-01-13     468\n",
       "2010-01-14     468\n",
       "2010-01-15     468\n",
       "2010-01-19     468\n",
       "2010-01-20     468\n",
       "2010-01-21     468\n",
       "2010-01-22     468\n",
       "2010-01-25     468\n",
       "2010-01-26     468\n",
       "2010-01-27     468\n",
       "2010-01-28     468\n",
       "2010-01-29     468\n",
       "2010-02-01     468"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instructor notes\n",
    "# Let's look at how many stocks have data for each date\n",
    "counts = stocks[['symbol']].groupby('date').count()\n",
    "counts.head(20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Number of stocks with data on each date')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instructor notes continued\n",
    "# This is much clearer with a quick visualization\n",
    "sns.barplot(x=counts.index, y=counts['symbol'])\n",
    "plt.title('Number of stocks with data on each date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructor notes: \n",
    "\n",
    "This display shows us that the most stocks are available on the latest date. This is an indication that we may have survivor bias. A bias in financial datasets where securities representing firms that go out of business are not included.  \n",
    "\n",
    "We cannot yet be sure that we have for the survivorship bias, but it is something to note.  Students might want to investigate this later. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Feature engineering\n",
    "For modelling data with machine learning, it is helpful to transform the data into a form that is closer to the theoretical expectations where the ML models should perform well. Let's transform the data into returns and generate other features.  We will transform returns with logarithms based on financial research that log returns are closer to normally distributed and (statistically) stable. \n",
    "\n",
    "**The function below is just a sample of feature transformations.  Taking the logarithms can help deal with skewed data as we saw we have in the pandas-profile report.**\n",
    "\n",
    "To be honest, which variables you use and how you transform them is largely dependent on domain expertise and traditions of the field. It can also be a matter of trial and error, although that can lead to overfitting.  We will discuss overfitting a little bit later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_target_generation(df):\n",
    "    \"\"\"\n",
    "    df: a pandas dataframe containing numerical columns\n",
    "    num_days_ahead: an integer that can be used to shift the prediction value from the future into a prior row.\n",
    "    \"\"\"\n",
    "\n",
    "    # The following line ensures the data is in date order    \n",
    "    features = pd.DataFrame(index=df.index).sort_index() \n",
    "    features['f01'] = np.log(df.close / df.open) # intra-day log return\n",
    "    features['f02'] = np.log(df.open / df.close.shift(1)) # overnight log return\n",
    "\n",
    "    features['f03'] = df.volume # try both regular and log volume\n",
    "    features['f04'] = np.log(df.volume) \n",
    "    features['f05'] = df.volume.diff() # 1-day absolute change in volume\n",
    "    features['f06'] = df.volume.pct_change() # 1-day relative change in volume\n",
    "    # The following are rolling averages of different periods\n",
    "    features['f07'] = df.volume.rolling(5, min_periods=1).mean().apply(np.log)\n",
    "    features['f08'] = df.volume.rolling(10, min_periods=1).mean().apply(np.log)\n",
    "    features['f09'] = df.volume.rolling(30, min_periods=1).mean().apply(np.log)\n",
    "\n",
    "    # More of our original data: low, high and close\n",
    "    features['f10'] = df.low \n",
    "    features['f11'] = df.high\n",
    "    features['f12'] = df.close\n",
    "    # The Intraday trading spread measures how far apart the high and low are\n",
    "    features['f13'] = df.high - df.low \n",
    "    # These are log returns over different time periods \n",
    "    features['f14'] = np.log(df.close / df.close.shift(1)) # 1 day log return\n",
    "    features['f15'] = np.log(df.close / df.close.shift(5)) # 5 day log return\n",
    "    features['f16'] = np.log(df.close / df.close.shift(10)) # 10 day log return\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Machine Learning, we need to predict something, typically called our target or predictor. \n",
    "\n",
    "Let's predict the value of the stock price 10 days into the future, using \"prediction_horizon\".  Here 10 is a hyperparameter that is somewhat arbitrary.  We may want to try different horizons to see if we are better at predicting the near future or the long term.  \n",
    "\n",
    "The ticker lets us start by testing on a single stock for speed in training.  \n",
    "\n",
    "We want to look at different periods of history to see how we do.  We will use overlapping sets with n_splits.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's generate a list of tickers so we can easily select them\n",
    "ticker_list = stocks.symbol.unique()\n",
    "\n",
    "# these are hyperparameters you can play with or tune\n",
    "prediction_horizon = -5 # this is a negative number by convention\n",
    "ticker = 'MSFT' # choose any ticker\n",
    "n_splits = 5 \n",
    "\n",
    "# Make an individual model for each ticker/symbol\n",
    "features = feature_target_generation(stocks[stocks.symbol==ticker])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Preparing and splitting our data\n",
    "It is important that we separate our training and test data.  Since our rows are already time ordered, we can easily do splits.  This is one of the areas where times series data is different from other machine learning problems.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeSeriesSplit(max_train_size=None, n_splits=5)\n"
     ]
    }
   ],
   "source": [
    "# We are trying to predict the price prediction_horizon days in the future.  So we take the future value and move it prediction_horizon into the past to line up our data in the Scikit-learn format.  \n",
    "y = features.f12.shift(prediction_horizon)\n",
    "# The latest (prediction_horizon) rows will have nans because we have no future data, so let's drop them.\n",
    "shifted = ~np.isnan(y)\n",
    "X = features[y.notna()] # Remove the rows that do not have valid target values\n",
    "y = y[shifted] # Remove the rows that do not have valid target values\n",
    "\n",
    "# Split the history into different backtesting regimes\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "print(tscv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1762 entries, 2010-01-04 to 2016-12-30\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   f01     1762 non-null   float64\n",
      " 1   f02     1761 non-null   float64\n",
      " 2   f03     1762 non-null   float64\n",
      " 3   f04     1762 non-null   float64\n",
      " 4   f05     1761 non-null   float64\n",
      " 5   f06     1761 non-null   float64\n",
      " 6   f07     1762 non-null   float64\n",
      " 7   f08     1762 non-null   float64\n",
      " 8   f09     1762 non-null   float64\n",
      " 9   f10     1762 non-null   float64\n",
      " 10  f11     1762 non-null   float64\n",
      " 11  f12     1762 non-null   float64\n",
      " 12  f13     1762 non-null   float64\n",
      " 13  f14     1761 non-null   float64\n",
      " 14  f15     1757 non-null   float64\n",
      " 15  f16     1752 non-null   float64\n",
      "dtypes: float64(16)\n",
      "memory usage: 234.0 KB\n"
     ]
    }
   ],
   "source": [
    " # Review the features\n",
    " features.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Building our first model\n",
    "This is a regression problem.  Why is that so? \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructor notes:\n",
    "\n",
    "This is a regression problem because it is predicting a price, which is a continuous value.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression\n",
    "In our ML framework we can use linear regression, just as in standard statistics or econometrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_ts_report(model, tscv, X, y, impute=False):\n",
    "    \"\"\"\n",
    "    Fit the model and then run time series backtests.\n",
    "    \"\"\"\n",
    "    # Loop through the backtests\n",
    "    for train_ind, test_ind in tscv.split(X): \n",
    "        # Report on the time periods\n",
    "        print(f'Train is from {X.iloc[train_ind].index.min()} to {X.iloc[train_ind].index.max()}. ')\n",
    "        print(f'Test is from {X.iloc[test_ind].index.min()} to {X.iloc[test_ind].index.max()}. ')\n",
    "        # Generate training and testing features and target for each fold.\n",
    "        X_train, X_test = X.iloc[train_ind], X.iloc[test_ind]\n",
    "        y_train, y_test = y.iloc[train_ind], y.iloc[test_ind]\n",
    "\n",
    "        if impute==True:\n",
    "            # Since linear regression cannot deal with NaN, we need to impute.  There may be the better choices.\n",
    "            X_train.fillna(df.mean(), inplace=True)\n",
    "            X_test.fillna(df.mean(), inplace=True)\n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict and measure on the training data\n",
    "        y_pred_train = model.predict(X_train) \n",
    "        print(\"Training results:\")\n",
    "        print(\"RMSE:\", mean_squared_error(y_train, y_pred_train, squared=False))\n",
    "\n",
    "        # Predict and measure on the testing data\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        print(\"Test results:\")\n",
    "        print(\"RMSE:\", mean_squared_error(y_test, y_pred_test, squared=False))\n",
    "        print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train is from 2010-01-04 00:00:00 to 2011-03-08 00:00:00. \n",
      "Test is from 2011-03-09 00:00:00 to 2012-05-03 00:00:00. \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-bee9678e8a95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Fit and report on a linear model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel_ts_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtscv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimpute\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-5d8a6d51f2b1>\u001b[0m in \u001b[0;36mmodel_ts_report\u001b[0;34m(model, tscv, X, y, impute)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimpute\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m# Since linear regression cannot deal with NaN, we need to impute.  There may be the better choices.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# Fit and report on a linear model\n",
    "lm = LinearRegression()\n",
    "model_ts_report(lm, tscv, X, y, impute=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we look at our results, we can see that in each period we do better in training than in testing.  That is typical of finance and machine learning more generally. \n",
    "Interestingly, we are able to explain 90% of the variance with our first linear model.  \n",
    "\n",
    "If you have questions about the root-mean-squared-error (RMSE), please see the Microsoft learn module on machine learning.\n",
    "\n",
    "#### Ensemble Model\n",
    "Let's try a Random Forest, which is a commonly used model that blends a group of decision trees, each of which have access to a sub-sample of features.  It is commonly used because it it tends to work well with relatively little tuning of hyperparameters and is somewhat less likely to overfit.  This is NOT a classic model commonly used in econometrics, mainly because it does not have a linear structure that corresponds with econometric theory.  However, it is often used in predictions for items other than finance.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initiate a Random Forest\n",
    "rf = RandomForestRegressor()\n",
    "model_ts_report(rf, tscv, X, y, impute=True) # Report on the random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using a Random Forest, we are able to bring down our training data error metrics by a lot (over 50% decrease on RMSE)!  However, our test results are not as good for most of the time slices.  This is an indication that we are *overfitting* our model to the training data.  This model would likely not do as well in production as it would in our backtests.  Why?  Because our models have not done well on any of the new data, outside the time period during which they were trained. \n",
    "\n",
    "### Open Ended Exercise\n",
    "\n",
    "Now is your turn to go ahead and improve these models.  Some areas that might help could be to: \n",
    "- Tune the existing models (Random forest has a number of parameters that may help) \n",
    "- Clean the existing data (Fill missing values better) \n",
    "- Try other models such as Support Vector Regressor, Extra Trees Regressor or ElasticNet \n",
    "- Try this for more stocks (Just becasue it did not work for one stock, it may still be useful for most stocks) \n",
    "- Get more features, through transformations or outside data  \n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructor notes: \n",
    "Here is an extra trees regressor.  This may do an even better job on training but it still is overfitting.  To have a production useable model we would need to improve performance on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train an extra trees regressor\n",
    "et = ExtraTreesRegressor(n_estimators=100, max_depth=4)\n",
    "model_ts_report(et, tscv, X, y, impute=True) # Report on the extra trees, an extension of the random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train is from 2010-01-04 00:00:00 to 2011-03-08 00:00:00. \n",
      "Test is from 2011-03-09 00:00:00 to 2012-05-03 00:00:00. \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-de01130d5965>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# this is the change\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mxgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel_ts_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtscv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimpute\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Report on the extra trees, an extension of the random forest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-5d8a6d51f2b1>\u001b[0m in \u001b[0;36mmodel_ts_report\u001b[0;34m(model, tscv, X, y, impute)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimpute\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m# Since linear regression cannot deal with NaN, we need to impute.  There may be the better choices.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# This is a different package that is at the \n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# this is the change\n",
    "xgb = XGBRegressor(n_jobs=4, n_estimators=200)\n",
    "model_ts_report(xgb, tscv, X, y, impute=True) # Report on the extra trees, an extension of the random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
